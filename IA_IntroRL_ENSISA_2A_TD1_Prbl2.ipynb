{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "i38qZPSHmDVs",
    "ekYrPhAGkAfM",
    "3zlRobQekELk",
    "id0Re9bnkWRP",
    "1rJLFmZYk0I1",
    "8FvleqV5onq9"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> Import libraries to use\n",
    "\n"
   ],
   "metadata": {
    "id": "JIuzZH7gj7Yu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "id": "1n-L9pacjmBA",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.146321Z",
     "start_time": "2024-11-05T09:40:29.142777Z"
    }
   },
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "source": [
    ">  # Introduction to numpy (Skip if you already are familiar)"
   ],
   "metadata": {
    "id": "i38qZPSHmDVs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    ">> Creating a 1D array"
   ],
   "metadata": {
    "id": "-wFkLk1kmeIn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-o1XD0Qmgxk",
    "outputId": "d5e1bb74-42be-449c-e57a-8e389c3368ef",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.201546Z",
     "start_time": "2024-11-05T09:40:29.197643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "source": [
    ">> Creating a 2D array\n"
   ],
   "metadata": {
    "id": "DWh4Q90Gmh32"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "print(a)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOS0jF1AmjTX",
    "outputId": "98649d5d-6738-499b-e907-bbcf7fe7a48f",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.265541Z",
     "start_time": "2024-11-05T09:40:29.259710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "source": [
    ">> Creating an array full of zeros\n"
   ],
   "metadata": {
    "id": "4Z_7BfvcmoPA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "a = np.zeros(shape=(10))\n",
    "print(a)\n",
    "a = np.zeros(shape=(5,2))\n",
    "print(a)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdGvmJ7gmFrF",
    "outputId": "96c1389b-8ff8-492b-9575-df4a3c38c711",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.331210Z",
     "start_time": "2024-11-05T09:40:29.324235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "source": [
    ">> Infinity in numpy"
   ],
   "metadata": {
    "id": "kV2byWmWmr9g"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(np.inf)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SMPoECVmygc",
    "outputId": "5ceafdaf-3f4d-4c98-e084-5b0409b5f127",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.396349Z",
     "start_time": "2024-11-05T09:40:29.389789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "source": [
    ">> Max and Argmax"
   ],
   "metadata": {
    "id": "FCi8vs49mz44"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "a = np.array([2,1,4,3])\n",
    "print(np.max(a))\n",
    "print(np.argmax(a))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ailb-V76nSqc",
    "outputId": "69c91264-9121-434c-8a96-a258748ad558",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.457738Z",
     "start_time": "2024-11-05T09:40:29.452428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "source": [
    ">> From list to Numpy"
   ],
   "metadata": {
    "id": "6XpkQzTfnXMU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "l = [1,2,3,4]\n",
    "print(l)\n",
    "print(np.asarray(l))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wdFdBaOncQI",
    "outputId": "0a5aa25a-5bee-4443-adaf-87bbcf0c1216",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.520803Z",
     "start_time": "2024-11-05T09:40:29.516174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "source": [
    ">> Random in numpy"
   ],
   "metadata": {
    "id": "PgNawY2LngKt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Array of Random integers ranging from 1 to 10 (with any size you want)\n",
    "a = np.random.randint(low=1, high=10, size=(5,2))\n",
    "print(a)\n",
    "\n",
    "# Array of random elements of a list with any size you want\n",
    "a = np.random.choice([0,1,2], size=(2,))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyopXlWsnjK1",
    "outputId": "80981877-04e6-4f31-ff13-933c7a2103a5",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.584304Z",
     "start_time": "2024-11-05T09:40:29.578673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 1]\n",
      " [2 1]\n",
      " [8 4]\n",
      " [8 8]\n",
      " [5 8]]\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "source": [
    ">> Shapes in numpy"
   ],
   "metadata": {
    "id": "abjqoNDSoAD6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "a = np.random.randint(low=1, high=5, size=(4,2))\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "# Reshape a to a vector of shape = (8,1)\n",
    "a = a.reshape((8,1))\n",
    "print(a.shape)\n",
    "print(a)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vN2gUoZEoCbE",
    "outputId": "bb7cb91f-7983-4bc9-d9a2-60f27017986a",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.646085Z",
     "start_time": "2024-11-05T09:40:29.641445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[[2 4]\n",
      " [3 2]\n",
      " [2 4]\n",
      " [1 2]]\n",
      "(8, 1)\n",
      "[[2]\n",
      " [4]\n",
      " [3]\n",
      " [2]\n",
      " [2]\n",
      " [4]\n",
      " [1]\n",
      " [2]]\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-defined utilities"
   ],
   "metadata": {
    "id": "ekYrPhAGkAfM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "int_to_char = {\n",
    "    0 : 'u',\n",
    "    1 : 'r',\n",
    "    2 : 'd',\n",
    "    3 : 'l'\n",
    "}\n",
    "\n",
    "policy_one_step_look_ahead = {\n",
    "    0 : [-1,0],\n",
    "    1 : [0,1],\n",
    "    2 : [1,0],\n",
    "    3 : [0,-1]\n",
    "}\n",
    "\n",
    "def policy_int_to_char(pi,n):\n",
    "\n",
    "\n",
    "    pi_char = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if (i, j) == (0, 0) or (i, j) == (n - 1, n - 1):\n",
    "                pi_char.append(' ')  # Represent terminal states with a space\n",
    "                continue\n",
    "\n",
    "            # Find the action with probability 1 (assuming deterministic policy)\n",
    "            action = np.argmax(pi[i, j])\n",
    "\n",
    "            # Use the action index to get the corresponding character\n",
    "            pi_char.append(int_to_char[action])\n",
    "\n",
    "        pi_char.append('\\n')  # Add a newline character at the end of each row\n",
    "\n",
    "    return ''.join(pi_char)"
   ],
   "metadata": {
    "id": "3kXEezQ_jnoP",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.704679Z",
     "start_time": "2024-11-05T09:40:29.700124Z"
    }
   },
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1- Policy evaluation"
   ],
   "metadata": {
    "id": "3zlRobQekELk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def policy_evaluation(n,pi,v,Gamma,threshhold, max_iterations = 10000):\n",
    "      \"\"\"\n",
    "        This function should return the value function that follows the policy pi.\n",
    "        Use the stopping criteria given in the problem statement.\n",
    "      \"\"\"\n",
    "      reward = -1\n",
    "      iteration = 0\n",
    "      while True:\n",
    "            delta = 0\n",
    "            \n",
    "            iteration += 1\n",
    "            \n",
    "            # if iteration % 100 == 0:             \n",
    "            #    print(\"policy evaluation : \",iteration)\n",
    "\n",
    "    \n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if (i, j) == (0, 0) or (i, j) == (n-1, n-1):\n",
    "                        continue  # Skip terminal states\n",
    "    \n",
    "                    v_old = v[i, j]\n",
    "                    v_new = 0\n",
    "    \n",
    "                    for action in range(4):\n",
    "                        i_prime = i + policy_one_step_look_ahead[action][0]\n",
    "                        j_prime = j + policy_one_step_look_ahead[action][1]\n",
    "    \n",
    "                        if not (0 <= i_prime < n and 0 <= j_prime < n):\n",
    "                            i_prime, j_prime = i, j\n",
    "    \n",
    "                        v_new += pi[i, j, action] * (reward + Gamma * v[i_prime, j_prime])\n",
    "                    v[i, j] = v_new\n",
    "                    delta = max(delta, abs(v_old - v_new))\n",
    "            if delta < threshhold or iteration >= max_iterations:\n",
    "                break\n",
    "    \n",
    "      return v\n",
    "    \n",
    "  \n",
    "  \n"
   ],
   "metadata": {
    "id": "N7_2lpTAkHAJ",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.756081Z",
     "start_time": "2024-11-05T09:40:29.751189Z"
    }
   },
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2- Policy improvement"
   ],
   "metadata": {
    "id": "id0Re9bnkWRP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def policy_improvement(n,pi,v,Gamma):\n",
    "      \"\"\"\n",
    "        This function should return the new policy by acting in a greedy manner.\n",
    "        The function should return as well a flag indicating if the output policy\n",
    "        is the same as the input policy.\n",
    "    \n",
    "        Example:\n",
    "          return new_pi, True if new_pi = pi for all states\n",
    "          else return new_pi, False\n",
    "      \"\"\"\n",
    "      new_pi = np.zeros((n, n, 4))\n",
    "      reward = -1\n",
    "      policy_stable = True\n",
    "    \n",
    "      for i in range(n):\n",
    "            for j in range(n):\n",
    "                if (i, j) == (0, 0) or (i, j) == (n-1, n-1):\n",
    "                    continue\n",
    "    \n",
    "                q_values = np.zeros(4)\n",
    "                for action in range(4):\n",
    "                    i_prime = i + policy_one_step_look_ahead[action][0]\n",
    "                    j_prime = j + policy_one_step_look_ahead[action][1]\n",
    "    \n",
    "                    if i_prime < 0 or i_prime >= n or j_prime < 0 or j_prime >= n:\n",
    "                        i_prime, j_prime = i, j\n",
    "    \n",
    "                    q_values[action] = reward + Gamma * v[i_prime, j_prime]\n",
    "    \n",
    "                max_q = np.max(q_values)\n",
    "                best_actions = [action for action in range(4) if q_values[action] == max_q]\n",
    "    \n",
    "                for action in range(4):\n",
    "                    if action in best_actions:\n",
    "                        new_pi[i, j, action] = 1 / len(best_actions)\n",
    "                    else:\n",
    "                        new_pi[i, j, action] = 0\n",
    "    \n",
    "                if not np.array_equal(new_pi[i, j], pi[i, j]):\n",
    "                    policy_stable = False\n",
    "    \n",
    "      return new_pi, policy_stable\n",
    "  \n",
    "  "
   ],
   "metadata": {
    "id": "eC8zswV7kZPF",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.812255Z",
     "start_time": "2024-11-05T09:40:29.804230Z"
    }
   },
   "outputs": [],
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3- Policy Initialization"
   ],
   "metadata": {
    "id": "1rJLFmZYk0I1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def policy_initialization(n):\n",
    "  \"\"\"\n",
    "    This function should return the initial random policy for all states.\n",
    "  \"\"\"\n",
    "  pi = np.zeros((n, n, len(policy_one_step_look_ahead)))\n",
    "  \n",
    "  \n",
    "\n",
    "  for i in range(n):\n",
    "      for j in range(n):\n",
    "          if (i, j) == (0, 0) or (i, j) == (n-1, n-1):\n",
    "              pi[i, j] = [0, 0, 0, 0]\n",
    "          else:\n",
    "              random_action = np.random.choice(len(policy_one_step_look_ahead))\n",
    "              pi[i, j, random_action] = 1\n",
    "\n",
    "  return pi\n",
    "  "
   ],
   "metadata": {
    "id": "xpuOHJeIk2K_",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.864829Z",
     "start_time": "2024-11-05T09:40:29.860179Z"
    }
   },
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4- Policy Iteration algorithm"
   ],
   "metadata": {
    "id": "rfeVN5fQlBt8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def policy_iteration(n,Gamma,threshhold, max_iterations = 10000):\n",
    "\n",
    "    pi = policy_initialization(n=n)\n",
    "\n",
    "    v = np.zeros(shape=(n,n))\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        #if iteration % 100 == 0:\n",
    "        #print(\"policy iteration : \",iteration)\n",
    "\n",
    "        v = policy_evaluation(n=n,v=v,pi=pi,threshhold=threshhold,Gamma=Gamma)\n",
    "\n",
    "        pi , pi_stable = policy_improvement(n=n,pi=pi,v=v,Gamma=Gamma)\n",
    "\n",
    "        if pi_stable or iteration >= max_iterations:\n",
    "\n",
    "            break\n",
    "\n",
    "    return pi , v"
   ],
   "metadata": {
    "id": "g7hnjz0PlFD4",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:29.917683Z",
     "start_time": "2024-11-05T09:40:29.912282Z"
    }
   },
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Code to Test"
   ],
   "metadata": {
    "id": "8FvleqV5onq9"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hntGpzW-jZk3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7cef0988-b63c-46cd-d047-0c1e33c72e39",
    "ExecuteTime": {
     "end_time": "2024-11-05T09:40:30.873902Z",
     "start_time": "2024-11-05T09:40:29.977202Z"
    }
   },
   "source": [
    "n = 4\n",
    "\n",
    "Gamma = [0.8,0.9,1]\n",
    "\n",
    "threshhold = 1e-4\n",
    "\n",
    "for _gamma in Gamma:\n",
    "\n",
    "    pi , v = policy_iteration(n=n,Gamma=_gamma,threshhold=threshhold)\n",
    "\n",
    "    pi_char = policy_int_to_char(n=n,pi=pi)\n",
    "\n",
    "    print()\n",
    "    print(\"Gamma = \",_gamma)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(pi_char)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print(v)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy iteration :  1\n",
      "policy iteration :  2\n",
      "policy iteration :  3\n",
      "policy iteration :  4\n",
      "\n",
      "Gamma =  0.8\n",
      "\n",
      " lld\n",
      "uuud\n",
      "uurd\n",
      "urr \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.   -1.   -1.8  -2.44]\n",
      " [-1.   -1.8  -2.44 -1.8 ]\n",
      " [-1.8  -2.44 -1.8  -1.  ]\n",
      " [-2.44 -1.8  -1.    0.  ]]\n",
      "policy iteration :  1\n",
      "policy iteration :  2\n",
      "policy iteration :  3\n",
      "policy iteration :  4\n",
      "\n",
      "Gamma =  0.9\n",
      "\n",
      " lld\n",
      "uuud\n",
      "uurd\n",
      "urr \n",
      "\n",
      "\n",
      "\n",
      "[[ 0.   -1.   -1.9  -2.71]\n",
      " [-1.   -1.9  -2.71 -1.9 ]\n",
      " [-1.9  -2.71 -1.9  -1.  ]\n",
      " [-2.71 -1.9  -1.    0.  ]]\n",
      "policy iteration :  1\n",
      "policy evaluation :  100\n",
      "policy evaluation :  200\n",
      "policy evaluation :  300\n",
      "policy evaluation :  400\n",
      "policy evaluation :  500\n",
      "policy evaluation :  600\n",
      "policy evaluation :  700\n",
      "policy evaluation :  800\n",
      "policy evaluation :  900\n",
      "policy evaluation :  1000\n",
      "policy evaluation :  1100\n",
      "policy evaluation :  1200\n",
      "policy evaluation :  1300\n",
      "policy evaluation :  1400\n",
      "policy evaluation :  1500\n",
      "policy evaluation :  1600\n",
      "policy evaluation :  1700\n",
      "policy evaluation :  1800\n",
      "policy evaluation :  1900\n",
      "policy evaluation :  2000\n",
      "policy evaluation :  2100\n",
      "policy evaluation :  2200\n",
      "policy evaluation :  2300\n",
      "policy evaluation :  2400\n",
      "policy evaluation :  2500\n",
      "policy evaluation :  2600\n",
      "policy evaluation :  2700\n",
      "policy evaluation :  2800\n",
      "policy evaluation :  2900\n",
      "policy evaluation :  3000\n",
      "policy evaluation :  3100\n",
      "policy evaluation :  3200\n",
      "policy evaluation :  3300\n",
      "policy evaluation :  3400\n",
      "policy evaluation :  3500\n",
      "policy evaluation :  3600\n",
      "policy evaluation :  3700\n",
      "policy evaluation :  3800\n",
      "policy evaluation :  3900\n",
      "policy evaluation :  4000\n",
      "policy evaluation :  4100\n",
      "policy evaluation :  4200\n",
      "policy evaluation :  4300\n",
      "policy evaluation :  4400\n",
      "policy evaluation :  4500\n",
      "policy evaluation :  4600\n",
      "policy evaluation :  4700\n",
      "policy evaluation :  4800\n",
      "policy evaluation :  4900\n",
      "policy evaluation :  5000\n",
      "policy evaluation :  5100\n",
      "policy evaluation :  5200\n",
      "policy evaluation :  5300\n",
      "policy evaluation :  5400\n",
      "policy evaluation :  5500\n",
      "policy evaluation :  5600\n",
      "policy evaluation :  5700\n",
      "policy evaluation :  5800\n",
      "policy evaluation :  5900\n",
      "policy evaluation :  6000\n",
      "policy evaluation :  6100\n",
      "policy evaluation :  6200\n",
      "policy evaluation :  6300\n",
      "policy evaluation :  6400\n",
      "policy evaluation :  6500\n",
      "policy evaluation :  6600\n",
      "policy evaluation :  6700\n",
      "policy evaluation :  6800\n",
      "policy evaluation :  6900\n",
      "policy evaluation :  7000\n",
      "policy evaluation :  7100\n",
      "policy evaluation :  7200\n",
      "policy evaluation :  7300\n",
      "policy evaluation :  7400\n",
      "policy evaluation :  7500\n",
      "policy evaluation :  7600\n",
      "policy evaluation :  7700\n",
      "policy evaluation :  7800\n",
      "policy evaluation :  7900\n",
      "policy evaluation :  8000\n",
      "policy evaluation :  8100\n",
      "policy evaluation :  8200\n",
      "policy evaluation :  8300\n",
      "policy evaluation :  8400\n",
      "policy evaluation :  8500\n",
      "policy evaluation :  8600\n",
      "policy evaluation :  8700\n",
      "policy evaluation :  8800\n",
      "policy evaluation :  8900\n",
      "policy evaluation :  9000\n",
      "policy evaluation :  9100\n",
      "policy evaluation :  9200\n",
      "policy evaluation :  9300\n",
      "policy evaluation :  9400\n",
      "policy evaluation :  9500\n",
      "policy evaluation :  9600\n",
      "policy evaluation :  9700\n",
      "policy evaluation :  9800\n",
      "policy evaluation :  9900\n",
      "policy evaluation :  10000\n",
      "policy iteration :  2\n",
      "policy evaluation :  100\n",
      "policy evaluation :  200\n",
      "policy evaluation :  300\n",
      "policy evaluation :  400\n",
      "policy evaluation :  500\n",
      "policy evaluation :  600\n",
      "policy evaluation :  700\n",
      "policy evaluation :  800\n",
      "policy evaluation :  900\n",
      "policy evaluation :  1000\n",
      "policy evaluation :  1100\n",
      "policy evaluation :  1200\n",
      "policy evaluation :  1300\n",
      "policy evaluation :  1400\n",
      "policy evaluation :  1500\n",
      "policy evaluation :  1600\n",
      "policy evaluation :  1700\n",
      "policy evaluation :  1800\n",
      "policy evaluation :  1900\n",
      "policy evaluation :  2000\n",
      "policy evaluation :  2100\n",
      "policy evaluation :  2200\n",
      "policy evaluation :  2300\n",
      "policy evaluation :  2400\n",
      "policy evaluation :  2500\n",
      "policy evaluation :  2600\n",
      "policy evaluation :  2700\n",
      "policy evaluation :  2800\n",
      "policy evaluation :  2900\n",
      "policy evaluation :  3000\n",
      "policy evaluation :  3100\n",
      "policy evaluation :  3200\n",
      "policy evaluation :  3300\n",
      "policy evaluation :  3400\n",
      "policy evaluation :  3500\n",
      "policy evaluation :  3600\n",
      "policy evaluation :  3700\n",
      "policy evaluation :  3800\n",
      "policy evaluation :  3900\n",
      "policy evaluation :  4000\n",
      "policy evaluation :  4100\n",
      "policy evaluation :  4200\n",
      "policy evaluation :  4300\n",
      "policy evaluation :  4400\n",
      "policy evaluation :  4500\n",
      "policy evaluation :  4600\n",
      "policy evaluation :  4700\n",
      "policy evaluation :  4800\n",
      "policy evaluation :  4900\n",
      "policy evaluation :  5000\n",
      "policy evaluation :  5100\n",
      "policy evaluation :  5200\n",
      "policy evaluation :  5300\n",
      "policy evaluation :  5400\n",
      "policy evaluation :  5500\n",
      "policy evaluation :  5600\n",
      "policy evaluation :  5700\n",
      "policy evaluation :  5800\n",
      "policy evaluation :  5900\n",
      "policy evaluation :  6000\n",
      "policy evaluation :  6100\n",
      "policy evaluation :  6200\n",
      "policy evaluation :  6300\n",
      "policy evaluation :  6400\n",
      "policy evaluation :  6500\n",
      "policy evaluation :  6600\n",
      "policy evaluation :  6700\n",
      "policy evaluation :  6800\n",
      "policy evaluation :  6900\n",
      "policy evaluation :  7000\n",
      "policy evaluation :  7100\n",
      "policy evaluation :  7200\n",
      "policy evaluation :  7300\n",
      "policy evaluation :  7400\n",
      "policy evaluation :  7500\n",
      "policy evaluation :  7600\n",
      "policy evaluation :  7700\n",
      "policy evaluation :  7800\n",
      "policy evaluation :  7900\n",
      "policy evaluation :  8000\n",
      "policy evaluation :  8100\n",
      "policy evaluation :  8200\n",
      "policy evaluation :  8300\n",
      "policy evaluation :  8400\n",
      "policy evaluation :  8500\n",
      "policy evaluation :  8600\n",
      "policy evaluation :  8700\n",
      "policy evaluation :  8800\n",
      "policy evaluation :  8900\n",
      "policy evaluation :  9000\n",
      "policy evaluation :  9100\n",
      "policy evaluation :  9200\n",
      "policy evaluation :  9300\n",
      "policy evaluation :  9400\n",
      "policy evaluation :  9500\n",
      "policy evaluation :  9600\n",
      "policy evaluation :  9700\n",
      "policy evaluation :  9800\n",
      "policy evaluation :  9900\n",
      "policy evaluation :  10000\n",
      "policy iteration :  3\n",
      "policy iteration :  4\n",
      "\n",
      "Gamma =  1\n",
      "\n",
      " lld\n",
      "uuud\n",
      "uurd\n",
      "urr \n",
      "\n",
      "\n",
      "\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n"
     ]
    }
   ],
   "execution_count": 90
  }
 ]
}
